"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
"""
import sys
import os
import torch
from torch.utils.data import Subset
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.config import *
from src.data.dataset import CocoDetectionForFasterRCNN, get_num_classes, get_names_classes
from src.data.dataloader import create_data_loaders
from src.models.faster_rcnn import get_model, get_model_with_anchors, freeze_backbone, unfreeze_backbone
from src.models.metrics import calculate_all_metrics, get_metrics_history, reset_metrics_history
from src.training.trainer import train_one_epoch, save_checkpoint, save_best_model
from src.training.utils import setup_optimizer, setup_scheduler
from src.visualization.metrics_plots import plot_training_progress

def check_data_exists():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    img_dir, train_ann, val_ann = get_data_paths()
    
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    print(f"–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {img_dir} - {'–°–£–©–ï–°–¢–í–£–ï–¢' if img_dir.exists() else '–ù–ï –°–£–©–ï–°–¢–í–£–ï–¢'}")
    print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {train_ann} - {'–°–£–©–ï–°–¢–í–£–ï–¢' if train_ann.exists() else '–ù–ï –°–£–©–ï–°–¢–í–£–ï–¢'}")
    print(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {val_ann} - {'–°–£–©–ï–°–¢–í–£–ï–¢' if val_ann.exists() else '–ù–ï –°–£–©–ï–°–¢–í–£–ï–¢'}")
    
    if not all([img_dir.exists(), train_ann.exists(), val_ann.exists()]):
        print("\n–û–®–ò–ë–ö–ê: –ù–µ –≤—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω—ã!")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å–ª–µ–¥—É—é—â–∞—è:")
        print("VME_data/VME_CDSI_datasets/satellite_images/ [—Ñ–∞–π–ª—ã .tif]")
        print("VME_data/VME_CDSI_datasets/annotations_HBB/train.json")
        print("VME_data/VME_CDSI_datasets/annotations_HBB/val.json")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
    image_files = list(img_dir.glob("*.tif")) + list(img_dir.glob("*.jpg")) + list(img_dir.glob("*.png"))
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
    
    if len(image_files) == 0:
        print("–û–®–ò–ë–ö–ê: –í –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤!")
        return False
    
    return True

def main():
    print("=== –û–±—É—á–µ–Ω–∏–µ Faster R-CNN —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ ===")
    print(f"DATA_ROOT: {DATA_ROOT}")
    print(f"DEVICE: {DEVICE}")
    
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –º–µ—Ç—Ä–∏–∫ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è
    reset_metrics_history()
    loss_history_stage_a = []
    loss_history_stage_b = []
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    if not check_data_exists():
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    img_dir, train_ann, val_ann = get_data_paths()  
 
    # 2. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    print("\n2. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    try:
        train_dataset = CocoDetectionForFasterRCNN(root=str(img_dir), annFile=str(train_ann))
        val_dataset = CocoDetectionForFasterRCNN(root=str(img_dir), annFile=str(val_ann))
        
        # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ö–û–õ–ò–ß–ï–°–¢–í–û –î–ê–ù–ù–´–• –ï–°–õ–ò –í–ö–õ–Æ–ß–ï–ù DEBUG_MODE
        if DEBUG_MODE:
            train_dataset = Subset(train_dataset, indices=range(min(MAX_SAMPLES, len(train_dataset))))
            val_dataset = Subset(val_dataset, indices=range(min(MAX_SAMPLES, len(val_dataset))))

        print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö samples: {len(train_dataset)}")
        print(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö samples: {len(val_dataset)}")
        
        # –ü–æ–∫–∞–∂–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
        sample_img, sample_target = train_dataset[0]
        print(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {sample_img.shape}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø—Ä–∏–º–µ—Ä–µ: {len(sample_target['boxes'])}")
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {e}")
        return
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\n3. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    try:
        num_classes = get_num_classes(train_ann)
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∏–ª–∏ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ anchor'–∞–º–∏
        use_custom_anchors = True  # –ú–æ–∂–µ—Ç–µ –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ False –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        if use_custom_anchors:
            print("üéØ –ò—Å–ø–æ–ª—å–∑—É—é –º–æ–¥–µ–ª—å —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ anchor'–∞–º–∏")
            model = get_model_with_anchors(num_classes)
        else:
            print("üîß –ò—Å–ø–æ–ª—å–∑—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å")
            model = get_model(num_classes)
            
        model.to(DEVICE)

        classes = get_names_classes(train_ann)

        print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {len(classes)}")
        for name, id in classes.items():
            print(f"\t - {name}: (id:{id})")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        return
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
    print("\n4. –°–æ–∑–¥–∞–Ω–∏–µ DataLoader...")
    train_loader, val_loader = create_data_loaders(train_dataset, val_dataset)
    
    # 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
    print("\n5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞...")
    optimizer = setup_optimizer(model, LEARNING_RATE_STAGE_A)
    scheduler = setup_scheduler(optimizer, STEP_SIZE, GAMMA)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    model_dir = DATA_ROOT / "models"
    model_dir.mkdir(exist_ok=True)
    
    # 6. –°—Ç–∞–¥–∏—è A: –ó–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–π backbone
    print("\n6. –°—Ç–∞–¥–∏—è A: –û–±—É—á–µ–Ω–∏–µ —Å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º backbone...")
    freeze_backbone(model)
    
    for epoch in range(NUM_EPOCHS_STAGE_A):
        print(f"\n--- Epoch {epoch+1}/{NUM_EPOCHS_STAGE_A} ---")
        try:
            # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ
            avg_loss = train_one_epoch(model, optimizer, train_loader, DEVICE, epoch, "A")
            scheduler.step()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º loss –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
            loss_history_stage_a.append(avg_loss)

            # –í–´–ß–ò–°–õ–ï–ù–ò–ï –í–°–ï–• –ú–ï–¢–†–ò–ö (3 –º–µ—Ç—Ä–∏–∫–∏ + –≥—Ä–∞—Ñ–∏–∫–∏)
            accuracy = calculate_all_metrics(model, val_loader, DEVICE, "A", epoch)
            
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —ç–ø–æ—Ö–∏ {epoch+1}:")
            print(f"\tLoss: {avg_loss:.4f}")
            print(f"\tAccuracy (IoU Advanced): {accuracy:.4f}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
            checkpoint_path = model_dir / f"stage_a_epoch_{epoch+1}.pth"
            save_checkpoint(model, optimizer, scheduler, epoch, avg_loss, checkpoint_path)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —ç–ø–æ—Ö–∏ {epoch+1}: {e}")
            break
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è —Å—Ç–∞–¥–∏–∏ A
    print("\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è Stage A...")
    metrics_hist = get_metrics_history()
    accuracy_history_stage_a = metrics_hist['iou_advanced'][:NUM_EPOCHS_STAGE_A]  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ accuracy —Å—Ç–∞–¥–∏–∏ A
    plot_training_progress(loss_history_stage_a, accuracy_history_stage_a, "A")
    
    # 7. –°—Ç–∞–¥–∏—è B: –†–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–π backbone
    print("\n7. –°—Ç–∞–¥–∏—è B: –û–±—É—á–µ–Ω–∏–µ —Å —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º backbone...")
    unfreeze_backbone(model)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –º–µ–Ω—å—à–∏–º LR
    optimizer = setup_optimizer(model, LEARNING_RATE_STAGE_B)
    scheduler = setup_scheduler(optimizer, STEP_SIZE, GAMMA)
    
    for epoch in range(NUM_EPOCHS_STAGE_B):
        print(f"\n--- Stage B, Epoch {epoch+1}/{NUM_EPOCHS_STAGE_B} ---")
        try:
            # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ
            avg_loss = train_one_epoch(model, optimizer, train_loader, DEVICE, epoch, "B")
            scheduler.step()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º loss –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
            loss_history_stage_b.append(avg_loss)

            # –í–´–ß–ò–°–õ–ï–ù–ò–ï –í–°–ï–• –ú–ï–¢–†–ò–ö (3 –º–µ—Ç—Ä–∏–∫–∏ + –≥—Ä–∞—Ñ–∏–∫–∏)
            accuracy = calculate_all_metrics(model, val_loader, DEVICE, "B", epoch)
            
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —ç–ø–æ—Ö–∏ {epoch+1}:")
            print(f"\tLoss: {avg_loss:.4f}")
            print(f"\tAccuracy (IoU Advanced): {accuracy:.4f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
            checkpoint_path = model_dir / f"stage_b_epoch_{epoch+1}.pth"
            save_checkpoint(model, optimizer, scheduler, epoch, avg_loss, checkpoint_path)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —ç–ø–æ—Ö–∏ {epoch+1}: {e}")
            break
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è —Å—Ç–∞–¥–∏–∏ B
    print("\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è Stage B...")
    metrics_hist = get_metrics_history()
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ accuracy —Å—Ç–∞–¥–∏–∏ B (–ø–æ—Å–ª–µ–¥–Ω–∏–µ NUM_EPOCHS_STAGE_B –∑–Ω–∞—á–µ–Ω–∏–π)
    all_accuracy = metrics_hist['iou_advanced']
    accuracy_history_stage_b = all_accuracy[-NUM_EPOCHS_STAGE_B:]
    plot_training_progress(loss_history_stage_b, accuracy_history_stage_b, "B")
    
    # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    print("\n8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    final_model_path = model_dir / "final_faster_rcnn.pth"
    save_best_model(model, final_model_path)
    
    print("\n" + "="*60)
    print("=== –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û! ===")
    print("="*60)
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
    print(f"üìä –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {DATA_ROOT}/metrics_plots/")
    print("\nüìà –°–æ–∑–¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏:")
    print("   üìÅ simple_count/     - –ú–µ—Ç—Ä–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤")
    print("   üìÅ iou_basic/        - –ë–∞–∑–æ–≤–∞—è IoU –º–µ—Ç—Ä–∏–∫–∞")
    print("   üìÅ iou_advanced/     - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è IoU –º–µ—Ç—Ä–∏–∫–∞ (–æ—Å–Ω–æ–≤–Ω–∞—è)")
    print("   üìÅ comparison/       - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫")
    print("   üìÅ training_progress/ - –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è (Loss + Accuracy)")
    print("\nüéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –≤ –ø–∞–ø–∫–µ 'iou_advanced/'")
    
    # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    final_metrics = get_metrics_history()
    print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–´–ï MET–†–ò–ö–ò:")
    print(f"   Simple Count:    {final_metrics['simple_count'][-1]:.4f}")
    print(f"   IoU Basic:       {final_metrics['iou_basic'][-1]:.4f}")
    print(f"   IoU Advanced:    {final_metrics['iou_advanced'][-1]:.4f}")


if __name__ == "__main__":    
    main()