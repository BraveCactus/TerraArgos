"""
–ú–æ–¥—É–ª—å —Å 3 –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏
"""
from pathlib import Path
import torch
import pandas as pd
from torchvision.ops import box_iou
from src.config import BATCH_SIZE, DETECT_THRESHOLD, IOU_TRESHHOLD, DATA_ROOT
from src.visualization.metrics_plots import plot_metric_per_epoch, plot_all_metrics_comparison

# –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
metrics_history = {
    'simple_count': [],      # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å—á–µ—Ç–∞
    'iou_basic': [],         # –ë–∞–∑–æ–≤–∞—è IoU –º–µ—Ç—Ä–∏–∫–∞  
    'iou_advanced': []       # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è IoU –º–µ—Ç—Ä–∏–∫–∞
}

def calculate_simple_count_metric(model, dataloader, device, stage, epoch):
    """
    –ú–ï–¢–†–ò–ö–ê 1: Simple Count - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤
    """
    model.eval()    
    total_diff = 0
    total_true = 0

    with torch.no_grad():
        for images, targets in dataloader:
            images = [img.to(device) for img in images]            
            predictions = model(images)

            for pred, target in zip(predictions, targets):
                above_threshold = pred['scores'] > DETECT_THRESHOLD
                pred_count = len(pred['boxes'][above_threshold])
                true_count = len(target['boxes'])
                
                total_diff += abs(pred_count - true_count)
                total_true += true_count

    # Accuracy = 1 - —Å—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ
    if total_true > 0:
        accuracy = 1.0 - (total_diff / total_true)
        accuracy = max(0.0, min(1.0, accuracy))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0 –¥–æ 1
    else:
        accuracy = 1.0
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    metrics_history['simple_count'].append(accuracy)
    
    return accuracy

def calculate_iou_basic_metric(model, dataloader, device, stage, epoch):
    """
    –ú–ï–¢–†–ò–ö–ê 2: IoU Basic - –ø—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ IoU
    """
    model.eval()    
    total_tp, total_fp, total_fn = 0, 0, 0

    with torch.no_grad():
        for images, targets in dataloader:
            images = [img.to(device) for img in images]            
            predictions = model(images)

            for pred, target in zip(predictions, targets):
                above_threshold = pred['scores'] > DETECT_THRESHOLD
                pred_boxes = pred['boxes'][above_threshold]
                true_boxes = target['boxes'].to(device)

                pred_count = len(pred_boxes)
                true_count = len(true_boxes)

                # –°–ª—É—á–∞–π 1: –ù–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                if pred_count == 0 and true_count > 0:
                    total_fn += true_count
                # –°–ª—É—á–∞–π 2: –ù–µ—Ç –∏—Å—Ç–∏–Ω–Ω—ã—Ö bbox'–æ–≤  
                elif pred_count > 0 and true_count == 0:
                    total_fp += pred_count
                # –°–ª—É—á–∞–π 3: –ï—Å—Ç—å –∏ pred, –∏ true
                elif pred_count > 0 and true_count > 0:
                    iou_matrix = box_iou(pred_boxes, true_boxes)
                    
                    # –ü—Ä–æ—Å—Ç–æ–π matching
                    for true_idx in range(true_count):
                        best_iou = torch.max(iou_matrix[:, true_idx]).item()
                        if best_iou >= IOU_TRESHHOLD:
                            total_tp += 1
                        else:
                            total_fn += 1
                    
                    total_fp += max(0, pred_count - true_count)

    # Accuracy = TP / (TP + FP + FN)
    if (total_tp + total_fp + total_fn) > 0:
        accuracy = total_tp / (total_tp + total_fp + total_fn)
    else:
        accuracy = 0.0
    
    metrics_history['iou_basic'].append(accuracy)
    
    return accuracy

def calculate_iou_advanced_metric(model, dataloader, device, stage, epoch):
    """
    –ú–ï–¢–†–ò–ö–ê 3: IoU Advanced - –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å bipartite matching
    """
    model.eval()    
    total_tp, total_fp, total_fn = 0, 0, 0

    with torch.no_grad():
        for images, targets in dataloader:
            images = [img.to(device) for img in images]            
            predictions = model(images)

            for pred, target in zip(predictions, targets):
                above_threshold = pred['scores'] > DETECT_THRESHOLD
                pred_boxes = pred['boxes'][above_threshold]
                true_boxes = target['boxes'].to(device)

                pred_count = len(pred_boxes)
                true_count = len(true_boxes)

                if pred_count == 0 and true_count > 0:
                    total_fn += true_count
                elif pred_count > 0 and true_count == 0:
                    total_fp += pred_count
                elif pred_count > 0 and true_count > 0:
                    iou_matrix = box_iou(pred_boxes, true_boxes)
                    
                    # Bipartite matching
                    used_preds = set()
                    used_trues = set()
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ä—ã —Å —Ö–æ—Ä–æ—à–∏–º IoU
                    good_pairs = []
                    for pred_idx in range(pred_count):
                        for true_idx in range(true_count):
                            iou_val = iou_matrix[pred_idx, true_idx].item()
                            if iou_val >= IOU_TRESHHOLD:
                                good_pairs.append((iou_val, pred_idx, true_idx))
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ IoU (–ª—É—á—à–∏–µ first)
                    good_pairs.sort(reverse=True, key=lambda x: x[0])
                    
                    # –ñ–∞–¥–Ω—ã–π matching
                    for iou_val, pred_idx, true_idx in good_pairs:
                        if pred_idx not in used_preds and true_idx not in used_trues:
                            total_tp += 1
                            used_preds.add(pred_idx)
                            used_trues.add(true_idx)
                    
                    total_fp += pred_count - len(used_preds)
                    total_fn += true_count - len(used_trues)

    if (total_tp + total_fp + total_fn) > 0:
        accuracy = total_tp / (total_tp + total_fp + total_fn)
    else:
        accuracy = 0.0
    
    metrics_history['iou_advanced'].append(accuracy)
    
    return accuracy

def calculate_all_metrics(model, dataloader, device, stage, epoch):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –≤—Å–µ 3 –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏
    """
    print(f"üìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ - Stage {stage}, Epoch {epoch+1}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
    accuracy_simple = calculate_simple_count_metric(model, dataloader, device, stage, epoch)
    accuracy_iou_basic = calculate_iou_basic_metric(model, dataloader, device, stage, epoch)
    accuracy_iou_advanced = calculate_iou_advanced_metric(model, dataloader, device, stage, epoch)
    
    print(f"   Simple Count: {accuracy_simple:.4f}")
    print(f"   IoU Basic: {accuracy_iou_basic:.4f}")
    print(f"   IoU Advanced: {accuracy_iou_advanced:.4f}")
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    epochs = range(1, epoch + 2)  # –≠–ø–æ—Ö–∏ –æ—Ç 1 –¥–æ —Ç–µ–∫—É—â–µ–π
    
    for metric_name in metrics_history.keys():
        if len(metrics_history[metric_name]) > 0:
            values = metrics_history[metric_name]
            plot_metric_per_epoch(metric_name, stage, epochs, values)
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    plot_all_metrics_comparison(stage, metrics_history)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É (IoU Advanced)
    return accuracy_iou_advanced

def get_metrics_history():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
    return metrics_history.copy()

def reset_metrics_history():
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –º–µ—Ç—Ä–∏–∫"""
    global metrics_history
    metrics_history = {
        'simple_count': [],
        'iou_basic': [], 
        'iou_advanced': []
    }